logging.level.root=INFO

# sort,orderBook,aggregate,inputDb
application.taskType=inputDb

# spring task线程池
spring.threads.corePoolSize=25
spring.threads.maxPoolSize=50
spring.threads.queueCapacity=100
spring.threads.keepAliveSeconds=120
spring.threads.awaitTerminationSeconds=60
spring.threads.waitForTasksToCompleteOnShutdown=true
spring.threads.threadNamePrefix=rpTask--

#Kafka主题配置
ezei.platform=mtp,atp
kafka.topic.prefix.raw=rcpi_sse.
kafka.topic.prefix=rcps-sse.
kafka.topic.suffix=sorted
# 十档行情相关主题
kafka.topic.order=mtp.cnmf
kafka.topic.mtp.needSortSet=0004,0020,0991
kafka.topic.mtp.needsort=mtp.trdcnmf,mtp.ordcnmf
# kafka.topic.mtp.noneSortSet=0991
# kafka.topic.mtp.nonesort=mtp.nontrad,mtp.prvnews
# kafka.topic.atp.set=0103
# kafka.topic.atp.needsort=atp.tt,atp.to
# 数据入库相关主题
kafka.topic.ordbook=mtp.ordbook
kafka.topic.sinkset=0004,0020,0991
# kafka.topic.databaseSet=0001,0002,0003,0004,0005,0006,0020

# kafka消费组
kafka.consume.brokers=rcpjt002:9092,rcpjt003:9092,rcpjt004:9092
kafka.consume.keySerializerClass=org.apache.kafka.common.serialization.ByteArrayDeserializer
kafka.consume.valueSerializerClass=org.apache.kafka.common.serialization.ByteArrayDeserializer
kafka.consume.clientGroupId=rcps-examples
kafka.consume.autoCommit=false
kafka.consume.maxPartitionFetchBytes=4194304
kafka.consume.fetchMaxBytes=10485760
kafka.consume.pollDuration=3000
kafka.consume.maxPollRecords=2
kafka.consume.heartbeatIntervalMs=300
kafka.consume.maxPollIntervalMs=5000
kafka.consume.sessionTimeoutMs=60000

# kafka生产组
kafka.producer.brokers=rcpjt002:9092,rcpjt003:9092,rcpjt004:9092
kafka.producer.keySerializerClass=org.apache.kafka.common.serialization.StringSerializer
kafka.producer.valueSerializerClass=org.apache.kafka.common.serialization.StringSerializer
kafka.producer.acks=1
kafka.producer.retries=3
kafka.producer.requestTimeout=2000
kafka.producer.maxBlockMs=1000
kafka.producer.lingerMs=200
kafka.producer.bufferMemory=33554432
kafka.producer.maxInFlightsRequestsPerSession=1
kafka.producer.maxRequestSize=1000000
kafka.producer.batchSize=16384
kafka.producer.maxMsgSize=150
#kafka.producer.compressionType=gzip
kafka.producer.metadataTimeout=1000
kafka.producer.testOpen=false


#Zookeeper配置
# zookeeper.uri=10.112.103.2:2181,10.112.103.3:2181,10.112.103.4:2181
zookeeper.uri=rcpjt002:2181,rcpjt003:2181,rcpjt004:2181
zookeeper.max_retries=3
zookeeper.session_time_out=500000
zookeeper.base_sleep_time_ms=5000
zookeeper.namespace=rcp_process

# redis连接池：
spring.redis.pool.nodes:10.112.103.5:7001,10.112.103.6:7001,10.112.103.7:7001,10.112.103.5:7002,10.112.103.6:7002,10.112.103.7:7002
spring.redis.pool.password:sf@sf12dds
spring.redis.pool.maxRedirects:3
spring.redis.pool.maxIdle:30
spring.redis.pool.minIdle:1
spring.redis.pool.maxTotal:30
spring.redis.pool.max-active:30
spring.redis.pool.maxWaitMillis:500
spring.redis.pool.timeoutHours:8


#postgreSql数据库配置
spring.jpa.hibernate.ddl-auto=none
spring.jpa.show-sql=true
spring.druid.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.druid.datasource.driver-class-name=org.postgresql.Driver
spring.druid.datasource.username=bds_ngsp
spring.druid.datasource.password=Ssebdsngsp@2021
spring.druid.datasource.url=jdbc:postgresql://10.112.103.10:25308/nebula?currentSchema=pd_stage?reWriteBatchedStatements=true?reWriteBatchedInserts=true
#config druid
spring.druid.datasource.initial-size=5
spring.druid.datasource.min-idle=5
spring.druid.datasource.max-active=20
spring.druid.datasource.max-wait=10000
spring.druid.datasource.time-between-eviction-runs-millis=60000
spring.druid.datasource.min-evictable-idle-time-millis=30000
spring.druid.datasource.validation-query=SELECT 'x'
spring.druid.datasource.test-while-idle=true
spring.druid.datasource.test-on-borrow=true
spring.druid.datasource.test-on-return=false
spring.druid.datasource.pool-prepared-statements=true
spring.druid.datasource.filters=stat
#数据库操作配置
postgresql.batchsize=5000

# 线程池配置对象内容
thread.maxPoolSize=10
thread.blockQueenSize=20
thread.keepAliveTimeout=3600
thread.coreThreadSize=5
# batch date config
spring.batch.date=


########################## OLD
#EzEI连接配置
#ezei.username=monitor
#ezei.password=$3gSupv
#ezei.host=10.112.6.182
#ezei.port=16712
#ezei.datadate=20131225
#ezei.client.perpoll.max=10000
#ezei.client.watermark.high=100000
#ezei.client.watermark.low=30000

#维度数据初始化来源,db 数据库(默认)，file：临时文件
dimension.source=db
dimension.maxcounts=5000000